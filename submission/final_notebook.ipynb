{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hIKjEPlIiQj",
        "outputId": "896f2bce-e84c-4708-aec0-a5373e57dbed"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-rq44wV1IkrV"
      },
      "outputs": [],
      "source": [
        "# Import PyMuPDF library you've just installed (`fitz`) to work with PDF files\n",
        "import fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fw6Nc5jsIoXH"
      },
      "outputs": [],
      "source": [
        "#You can modify the filename below with any PDF path you upload\n",
        "pdf_path = \"../raw_data/document_to_anonymize.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gnsIrSq2Io7o"
      },
      "outputs": [],
      "source": [
        "# Define a function to extract all text from a PDF file. It reads every page and returns the combined text.\n",
        "\n",
        "def extract_text_from_pdf(path: str) -> str:\n",
        "    \"\"\"\n",
        "      Extracts text content from all pages of a PDF file.\n",
        "\n",
        "      Parameters:\n",
        "          path (str): The file path to the PDF document.\n",
        "\n",
        "      Returns:\n",
        "          str: The extracted text from the entire PDF.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    with fitz.open(path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aOi0zRPiIraQ"
      },
      "outputs": [],
      "source": [
        "#Defines a function to extract all the special characters in the text, in order to have a raw version of the text\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def remove_all_special_characters(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalizes and cleans a text string by removing accents, punctuation, and special characters.\n",
        "\n",
        "    Steps:\n",
        "        1. Converts accented characters to their ASCII equivalents.\n",
        "        2. Removes all characters except letters, numbers, and spaces.\n",
        "        3. Collapses multiple spaces into a single space.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The input string to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned and normalized string.\n",
        "    \"\"\"\n",
        "    text = unicodedata.normalize(\"NFD\", text)\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
        "\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xhjPOdSWIwZt"
      },
      "outputs": [],
      "source": [
        "# ðŸš€ Run this function to extract the text on your chosen PDF!\n",
        "\n",
        "raw_text = extract_text_from_pdf(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RelatÃ³rio de AdmissÃ£o - Centro MÃ©dico Lisboa \n",
            "Data: 15 de abril de 2025 \n",
            "ReferÃªncia: ADM-2025-04-15-089 \n",
            "InformaÃ§Ãµes do Paciente: \n",
            "Nome: * * * * \n",
            "Data de Nascimento: 12/03/1978 \n",
            "Sexo: Feminino \n",
            "NIF: * * * * * \n",
            "CartÃ£o de CidadÃ£o: * * * * * \n",
            "Morada: * * * * * \n",
            "Telefone: +* \n",
            "Email: * * * * \n",
            "NÃºmero da SeguranÃ§a Social: * * * * * * * \n",
            "HistÃ³rico MÃ©dico: \n",
            "A paciente * *, mulher caucasiana de 47 anos, compareceu Ã  consulta relatando dores \n",
            "abdominais intensas. Tem histÃ³rico de hipertensÃ£o e diabetes tipo 2, diagnosticada hÃ¡ 5 anos. Ã‰ \n",
            "HIV positivo desde 2018, atualmente com carga viral indetectÃ¡vel graÃ§as ao tratamento com \n",
            "antirretrovirais. \n",
            "A paciente relatou que sua famÃ­lia tem histÃ³rico de cancro da mama (mÃ£e falecida aos 52 anos) \n",
            "e doenÃ§a cardÃ­aca (pai e avÃ´ paterno). Exames genÃ©ticos realizados em 2022 indicaram \n",
            "predisposiÃ§Ã£o ao cancro de mama (mutaÃ§Ã£o BRCA1 positiva). \n",
            "InformaÃ§Ãµes Sociais e Comportamentais: \n",
            "Estado civil: Divorciada \n",
            "Filhos: 2 (*, 15 anos e *, 12 anos) \n",
            "ReligiÃ£o: CatÃ³lica praticante \n",
            "OcupaÃ§Ã£o: Professora universitÃ¡ria na Faculdade de Direito de Lisboa \n",
            "HÃ¡bitos: Ex-fumante (parou hÃ¡ 3 anos), consome Ã¡lcool socialmente (2-3 doses por semana) \n",
            "HistÃ³rico de uso de substÃ¢ncias: Tratamento para dependÃªncia de ansiolÃ­ticos em 2019 \n",
            "InformaÃ§Ãµes Financeiras: \n",
            "Seguro de saÃºde: Plano Premium SaÃºde Total, apÃ³lice nÂº * \n",
            "NÃºmero do cartÃ£o de crÃ©dito: * * * * * * * * (validade *, CVV *) \n",
            "Rendimento anual declarado: â‚¬* \n",
            "Dados BiomÃ©tricos: \n",
            "ImpressÃ£o digital registrada no sistema: ID-BIO-* \n",
            "Reconhecimento facial: FACE-ID-* \n",
            "Altura: 1,68m \n",
            "Peso: 72kg \n",
            "Tipo sanguÃ­neo: O+ \n",
            "PressÃ£o arterial na admissÃ£o: 145/90 mmHg \n",
            "Notas da Consulta: \n",
            "A paciente apresentou-se ansiosa durante a consulta, relatando problemas no trabalho \n",
            "relativamente Ã  elevada carga de responsabilidades que adquiriu. SensaÃ§Ã£o de cansaÃ§o, fadiga, \n",
            "e constante stress foram ditos fazer parte do seu dia-a-dia, no entanto, apresenta dificuldade em \n",
            "dormir/cumprir as horas indicadas de sono. \n",
            "Exames solicitados: hemograma completo, glicemia em jejum, perfil lipÃ­dico, funÃ§Ã£o hepÃ¡tica e \n",
            "renal, ultrassonografia abdominal. \n",
            "PrescriÃ§Ã£o: Metformina 850mg 2x/dia, Losartana 50mg 1x/dia, Alprazolam 0,5mg (apenas em \n",
            "caso de crises de ansiedade). \n",
            "Contatos de EmergÃªncia: \n",
            "Nome: * * * * \n",
            "Telefone: +* \n",
            "Email: * * * * \n",
            "Nome: * * * * \n",
            "Telefone: +* \n",
            "Assinatura Digital: \n",
            "Dr. * * \n",
            "CRM: * * * * * \n",
            "Especialidade: Medicina Interna \n",
            "Email: * * * * \n",
            "Telefone: +*\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        " \n",
        "# Replace this with your actual API key\n",
        "API_KEY = \"AIzaSyDW2cfHZQQZtNkCn5PKa_Uw1ZbsgBTd3B8\"\n",
        "API_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemma-3-12b-it:generateContent?key={API_KEY}\"\n",
        " \n",
        "def generate_content(prompt_text: str, temperature: float) -> dict:\n",
        "    \"\"\"Generates content based on the given prompt text and temperature.\n",
        " \n",
        "    Args:\n",
        "        prompt_text (str): The text prompt to generate content from.\n",
        "        temperature (float): The temperature parameter for controlling randomness.\n",
        "    \"\"\"\n",
        " \n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        " \n",
        "    body = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt_text}\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"generationConfig\": {\n",
        "            \"temperature\": temperature,\n",
        "            \"topK\":1,\n",
        "        }\n",
        "    }\n",
        " \n",
        "    response = requests.post(API_URL, headers=headers, json=body)\n",
        " \n",
        "    return response.json()\n",
        " \n",
        "def read_text_file(file_path: str) -> str:\n",
        "    \"\"\"Reads the content of a text file.\n",
        " \n",
        "    Args:\n",
        "        file_path (str): The path to the text file.\n",
        " \n",
        "    Returns:\n",
        "        str: The contents of the text file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        " \n",
        "# Define the anonymization prompt\n",
        "prompt = (\n",
        "    \"You are a specialist in text and document anonymization. Your task is to analyze the document that will be submitted and remove any sensitive or personal information contained within it.\\n\"\n",
        "    \"Your primary responsibility is to ensure that no individual can be identified from the anonymized document.\\n\"\n",
        "    \"## Information that needs to be removed includes, but is not limited to:\\n\"\n",
        "    \"- Names of individuals (e.g., Ana Correira)\\n\"\n",
        "    \"- Phone numbers (e.g., 1231242312)\\n\"\n",
        "    \"- Addresses (e.g., Example Street, 123, City)\\n\"\n",
        "    \"- Government data that can identify an individual, alone or in combination\\n\"\n",
        "    \"- Specific employment details that may identify the individual (e.g., Company Name)\\n\"\n",
        "    \"- Any other information that could indirectly identify an individual.\\n\"\n",
        " \n",
        "    \"## Anything that is not considered sensitive MUST NOT be removed and should remain intact. All words or information removed should be replaced with an asterisk (*).\\n\"\n",
        " \n",
        "    \"## Examples of anonymization:\\n\"\n",
        "    \"- Ana Correira -> * *\\n\"\n",
        "    \"- 1231242312 -> *\\n\"\n",
        "    \"- Example Street, 123, City -> * * * *\\n\"\n",
        " \n",
        "    \"Additionally, ensure that the formatting of the response remains identical to the original document, without any blank lines.\\n\"\n",
        "    \"Make sure that the resulting text does not contain any information that could identify individuals in any form or sensitive information about individuals.\\n\"\n",
        ")\n",
        " \n",
        "complete_prompt = prompt + raw_text  # Combine the prompt with the content of the document\n",
        "output = generate_content(complete_prompt, 0.0)\n",
        " \n",
        "# Get only the response text\n",
        "response_text = output.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '')\n",
        " \n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
